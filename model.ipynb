{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import MeCab\n",
    "import gensim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import ipadic\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim\n",
    "pyLDAvis.enable_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             content  negaposi\n",
      "0  ä»Šæ—¥ã€ã‚³ãƒ­ãƒŠç¦ã§ã„ã¤ã‚‚æ•°äººã—ã‹ã„ãªã„è¿‘æ‰€ã®é›»åœã«ã€ä¿®å­¦æ—…è¡Œç”ŸãŒãŸãƒ¼ãã•ã‚“ã„ã‚‹ã®ã‚’è¦‹ãŸã€‚\\nå°‘... -0.166667\n",
      "1  ã€Œã‚ã‹ã‚Šã‚„ã™ãã„ã„ãã‚‹ã€è¨€å‹•ã«ã¯çœ‰ã«å”¾ã‚’ã¤ã‘ã¦ç–‘ã„ã®çœ¼å·®ã—ã§å¯¾å¿œã™ã‚‹ã€ã¨ã„ã†ã®ã¯æœ€ä½é™åº¦ã®ã‚³... -0.333333\n",
      "2  ã‚„ã‚ŠãŸã„ã¨ã“ã‚ã§ã¯ã‚ã‚Šã¾ã™ãŒã¡ã‚“ã¡ã‚“ã¶ã‚‰ã¶ã‚‰ä»¥ä¸‹çœç•¥ğŸ˜‘\\n\\nã‚³ãƒ­ãƒŠç¦æ•…ä»£è¡¨è€…ä¸€åã®ã¿å‘¼ã°ã‚Œ... -0.142857\n",
      "3  ï¼œé€Ÿå ±ï¼æ–°å‹ã‚³ãƒ­ãƒŠæ–°è¦æ„ŸæŸ“ã€ç†Šæœ¬çœŒå†…ï¼“ï¼˜ï¼–äºº ï½œ 2022/6/2 16:07 - ç†Šæœ¬æ—¥æ—¥... -0.066667\n",
      "4  å²©æ‰‹ã§ï¼‘ï¼™ï¼‘äººã‚³ãƒ­ãƒŠæ„ŸæŸ“ â€“ ãƒ‡ãƒ¼ãƒªãƒ¼æ±åŒ—ãƒ‡ã‚¸ã‚¿ãƒ« - ãƒ‡ãƒ¼ãƒªãƒ¼æ±åŒ—ï½œå²©æ‰‹çœŒé–¢é€£ https... -0.142857\n"
     ]
    }
   ],
   "source": [
    "nega = pd.read_csv(\"./out/nega.csv\")\n",
    "print(nega.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse(tweet_temp):\n",
    "    t = MeCab.Tagger(ipadic.MECAB_ARGS)\n",
    "    temp1 = t.parse(tweet_temp)\n",
    "    temp2 = temp1.split(\"\\n\")\n",
    "    t_list = []\n",
    "    for keitaiso in temp2:\n",
    "        if keitaiso not in [\"EOS\", \"\"]:\n",
    "            word, hinshi = keitaiso.split(\"\\t\")\n",
    "            t_temp = [word] + hinshi.split(\",\")\n",
    "            if len(t_temp) != 10:\n",
    "                t_temp += [\"*\"]*(10-len(t_temp))\n",
    "            t_list.append(t_temp)\n",
    "    return t_list\n",
    "\n",
    "def parse_to_df(tweet_temp):\n",
    "    return pd.DataFrame(parse(tweet_temp),\n",
    "                        columns=[\"å˜èª\",\"å“è©\",\"å“è©ç´°åˆ†é¡1\",\n",
    "                                 \"å“è©ç´°åˆ†é¡2\",\"å“è©ç´°åˆ†é¡3\",\n",
    "                                 \"æ´»ç”¨å‹\",\"æ´»ç”¨å½¢\",\"åŸå½¢\",\"èª­ã¿\",\"ç™ºéŸ³\"])\n",
    "    \n",
    "def make_lda_docs(texts):\n",
    "    docs = []\n",
    "    for text in texts:\n",
    "        df = parse_to_df(text)\n",
    "        extract_df = df[(df[\"å“è©\"]+\"/\"+df[\"å“è©ç´°åˆ†é¡1\"]).isin([\"åè©/ä¸€èˆ¬\",\"åè©/å›ºæœ‰åè©\"])]\n",
    "        extract_df = extract_df[extract_df[\"åŸå½¢\"]!=\"*\"]\n",
    "        doc = []\n",
    "        for genkei in extract_df[\"åŸå½¢\"]:\n",
    "            doc.append(genkei)\n",
    "        docs.append(doc)\n",
    "    return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ã‚³ãƒ­ãƒŠ', 'è¿‘æ‰€', 'ä¿®å­¦æ—…è¡Œ', 'æ—¥å¸¸']\n"
     ]
    }
   ],
   "source": [
    "texts = nega[\"content\"].values\n",
    "docs = make_lda_docs(texts)\n",
    "print(docs[0])\n",
    "dictionary = gensim.corpora.Dictionary(docs)\n",
    "corpus = [dictionary.doc2bow(doc) for doc in docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ãƒ†ã‚­ã‚¹ãƒˆï¼š\n",
      "ä»Šæ—¥ã€ã‚³ãƒ­ãƒŠç¦ã§ã„ã¤ã‚‚æ•°äººã—ã‹ã„ãªã„è¿‘æ‰€ã®é›»åœã«ã€ä¿®å­¦æ—…è¡Œç”ŸãŒãŸãƒ¼ãã•ã‚“ã„ã‚‹ã®ã‚’è¦‹ãŸã€‚\n",
      "å°‘ã—ãšã¤æ—¥å¸¸ãŒæˆ»ã£ã¦ãã‚‹ã®ã‹ãªã€‚\n",
      " \n",
      "LDAã§èª­ã‚€å˜èªï¼š\n",
      "ã‚³ãƒ­ãƒŠ,è¿‘æ‰€,ä¿®å­¦æ—…è¡Œ,æ—¥å¸¸\n"
     ]
    }
   ],
   "source": [
    "print(\"ãƒ†ã‚­ã‚¹ãƒˆï¼š\")\n",
    "print(texts[0][:200])\n",
    "print(\" \")\n",
    "print(\"LDAã§èª­ã‚€å˜èªï¼š\")\n",
    "print(\",\".join(docs[0][:50]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_cluster = 4\n",
    "lda = gensim.models.LdaModel(\n",
    "                corpus=corpus,\n",
    "                id2word=dictionary,\n",
    "                num_topics=n_cluster,\n",
    "                minimum_probability=0.001,\n",
    "                passes=20,\n",
    "                update_every=0,\n",
    "                chunksize=10000,\n",
    "                random_state=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_lda = lda[corpus]\n",
    "arr = gensim.matutils.corpus2dense(\n",
    "        corpus_lda,\n",
    "        num_terms=n_cluster\n",
    ").T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ãƒˆãƒ”ãƒƒã‚¯-å˜èªåˆ†å¸ƒã®å¯è¦–åŒ–"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "lists = []\n",
    "for i in range(n_cluster):\n",
    "    temp_df = pd.DataFrame(lda.show_topic(i), columns=[\"word\", \"score\"])\n",
    "    temp_df[\"topic\"] = i\n",
    "    lists.append(temp_df)\n",
    "topic_word_df = pd.concat(lists, ignore_index=True)\n",
    "\n",
    "topic_word_df.to_csv(\"./out/topic_word_df.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "#topic_word_df[\"rank\"] = topic_word_df.groupby(\"topic\")[\"score\"].rank()\n",
    "#topic_word_df.pivot(index='topic', columns='rank', values='word')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis = pyLDAvis.gensim.prepare(lda, corpus, dictionary, sort_topics=False)\n",
    "pyLDAvis.save_html(vis, \"./out/pyldavis_output.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3a32b510a4ffeb2af8ce66afabf871f811236075ab5a792e8daead656a8b2e5f"
  },
  "kernelspec": {
   "display_name": "Python 3.6.13 ('dl')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
